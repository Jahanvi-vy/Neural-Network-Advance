{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012fdd9d-e742-445c-a60e-088dcbbc9bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cfeb61-904c-417d-b3e0-27ea503b5b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests==2.27.1  \n",
    "import os\n",
    "os.environ['CURL_CA_BUNDLE'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "719194dd-da82-4e7d-a6e1-4f03ff16521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_='bert-based-uncased'\n",
    "text='time files like an arrow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8527f97f-dbcd-443d-8d3e-01ea35e0e050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jv028u\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\jv028u\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f7507310fc4f1d994cee6b0dd34fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jv028u\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jv028u\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\jv028u\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\jv028u\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab760a88692a43f786c0492d7e53a2d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jv028u\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\jv028u\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86affb68786d401b96913e81fd652442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jv028u\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\jv028u\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e2eed9699b4bf983b83f038d7f1f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jv028u\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\jv028u\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_ckpt = \"bert-base-uncased\"\n",
    "text = \"time flies like an arrow\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "046fa936-eff9-45bc-920e-4020ce1e2c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e83c65c-fff3-4eaa-8a27-c6b360a14656",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efd376c7-fcb6-4a4a-bdff-55b20938a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c73fd53-bd87-47fb-9ed1-a30f3c5b512a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2051, 10029,  2066,  2019,  8612]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceb597c-d939-4842-b05f-7d2917b2d7c1",
   "metadata": {},
   "source": [
    "### 2. *Embedding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0ed0313-0efb-4b23-8d37-0ff1d7b886c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jv028u\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from transformers import AutoConfig\n",
    "config=AutoConfig.from_pretrained(model_ckpt)\n",
    "token_emb=nn.Embedding(config.vocab_size,config.hidden_size)\n",
    "input_embeds=token_emb(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c73811-b4e5-459d-9fcd-fdcbaafb0793",
   "metadata": {},
   "source": [
    "*AutoConfig:* loads the configuration for the BERT model,includes important hyperparameters like vocab_size (30522 tokens) and hidden_size (768).\n",
    "\n",
    "nn.Embedding:*  creates an embedding layer.  input token ID is mapped to a high-dimensional vector (768-dimensional in BERT's case).\n",
    "\n",
    "inputs_embeds:* Here, input token IDs are passed through the embedding layer, converting each token ID into a dense vector of size [768]. These are raw, non-contextual embeddings that do not yet include any position or sequence information.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6650a233-5657-4481-813d-11ac43eee436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6435,  0.9685,  0.2010,  ...,  0.0762, -0.5175, -0.7158],\n",
       "         [-1.9802, -0.0077,  1.6865,  ..., -0.0394, -0.2377, -1.7966],\n",
       "         [-0.6890, -1.3175, -0.8030,  ..., -2.6974,  0.1425, -0.6903],\n",
       "         [ 0.1641,  1.7179, -0.8291,  ...,  1.8245, -1.2870, -0.3912],\n",
       "         [-1.1103, -0.0307, -0.2500,  ..., -1.3880,  1.3403,  1.4526]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc3219-ec68-4bd0-b831-0bd0f3901972",
   "metadata": {},
   "source": [
    "### 3. *Attention Mechanism: Scaled Dot Product*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29d8fac5-fcfc-4936-b0f6-efdadd8ed8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from math import sqrt \n",
    "\n",
    "query=key=value=input_embeds\n",
    "dim_k=key.size(-1)\n",
    "\n",
    "scores=torch.bmm(query,key.transpose(1,2))/sqrt(dim_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bcaf2b3d-ee8d-4343-b917-c706835ab6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 5, 768]), torch.Size([1, 768, 5]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.size(), key.transpose(1,2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a24660e4-4646-498e-a1ae-61be30550d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " scores.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7b5cb86-2dc6-4241-bc77-d57f32b57c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[30.9423, -0.3590,  0.0889,  0.5369,  0.6388],\n",
       "         [-0.3590, 24.8945,  2.2607,  0.0989, -0.2881],\n",
       "         [ 0.0889,  2.2607, 27.0244,  0.5362, -0.2460],\n",
       "         [ 0.5369,  0.0989,  0.5362, 28.6788, -2.3923],\n",
       "         [ 0.6388, -0.2881, -0.2460, -2.3923, 28.3938]]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores \n",
    "#relation of words. influence of other words  to enecode particular word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef09374-daaa-4e4d-b44d-a9baf8597d97",
   "metadata": {},
   "source": [
    "### 4. *Attention Weights (Softmax)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f097f39-4f8e-4a16-922b-6af04ed1f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "weights = F.softmax(scores, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c37f5117-a357-45c6-b8eb-92cd877ea453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000e+00, 2.5470e-14, 3.9861e-14, 6.2389e-14, 6.9086e-14],\n",
       "         [1.0778e-11, 1.0000e+00, 1.4800e-10, 1.7037e-11, 1.1570e-11],\n",
       "         [2.0048e-12, 1.7591e-11, 1.0000e+00, 3.1358e-12, 1.4342e-12],\n",
       "         [5.9998e-13, 3.8718e-13, 5.9958e-13, 1.0000e+00, 3.2063e-14],\n",
       "         [8.8339e-13, 3.4962e-13, 3.6463e-13, 4.2632e-14, 1.0000e+00]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights \n",
    "#determine % of each input word should be used to encode word "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508e9afe-1e93-4e04-8408-02b9484dace9",
   "metadata": {},
   "source": [
    "### 5. *Weighted Sum: Update Embeddings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6629926e-fbad-4d37-93a8-49b1d6793d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_outputs=torch.bmm(weights,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c988dbff-7e92-4923-9576-81052c7730ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_outputs.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aefe07-2b7f-45a7-8c96-7aa2d2a922bb",
   "metadata": {},
   "source": [
    "- *torch.bmm:* Now that we have attention weights, we multiply them with the value vectors. This produces new embeddings where each word's representation is updated based on how much it attends to others.\n",
    "- gives context to each word  and realtion b/w words .\n",
    "- If the word \"flies\" pays 80% attention to \"time,\" its new embedding will be largely influenced by \"time.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "898e1f08-f89d-400b-a7d3-172cd86a817a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6435,  0.9685,  0.2010,  ...,  0.0762, -0.5175, -0.7158],\n",
       "         [-1.9802, -0.0077,  1.6865,  ..., -0.0394, -0.2377, -1.7966],\n",
       "         [-0.6890, -1.3175, -0.8030,  ..., -2.6974,  0.1425, -0.6903],\n",
       "         [ 0.1641,  1.7179, -0.8291,  ...,  1.8245, -1.2870, -0.3912],\n",
       "         [-1.1103, -0.0307, -0.2500,  ..., -1.3880,  1.3403,  1.4526]]],\n",
       "       grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_outputs  # Each score represents how much attention should be paid to other tokens in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d41987e-56ca-4a9d-aba9-43dd4d60172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value):\n",
    "    dim_k = query.size(-1)\n",
    "    scores = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k)\n",
    "    weights = F.softmax(scores, dim=-1) # # apply softmax along the last dimension of tensor, i.e., dimension of embedding features\n",
    "    return torch.bmm(weights, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d64aefb-3588-455c-b55d-7a6f3207fa67",
   "metadata": {},
   "source": [
    "### 6. *Attention Head*\n",
    "implements a single attention head in a Transformer model using PyTorch. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a92699ad-5390-43bd-9851-39072a05272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for one attention head\n",
    "class AttentionHead(nn.Module):\n",
    "    # initialize the class\n",
    "    def __init__(self, embed_dim, head_dim): # embed_dim=768, head_dim=64 -number of dimensions we want to project the hidden state to\n",
    "        # call the parent class\n",
    "        super().__init__()\n",
    "        # create the linear transformation layers\n",
    "        self.q = nn.Linear(embed_dim, head_dim) # project (1, 5, 768) -> (1, 5, 64)\n",
    "        self.k = nn.Linear(embed_dim, head_dim) # project (1, 5, 768) -> (1, 5, 64)\n",
    "        self.v = nn.Linear(embed_dim, head_dim) # project (1, 5, 768) -> (1, 5, 64)\n",
    "\n",
    "    # define the forward pass of the class\n",
    "    def forward(self, hidden_state):                         # hidden_state.size() = inputs_embeds.size() = (1, 5, 768) = (batch_size, seq_len, hidden_size) \n",
    "        # calculate the scaled dot product attention for one head \n",
    "        dim_k = self.k(hidden_state).size(-1)                # get the last dimension of the key after linear transformation   (1, 5, 64) -> 64\n",
    "        scores = torch.bmm(self.q(hidden_state),             # calculate the attention scores (1, 5, 64) * (1, 64, 5) = (1, 5, 5)\n",
    "                           self.k(hidden_state).transpose(1,2)) / sqrt(dim_k) \n",
    "        attn_weights = F.softmax(scores, dim=-1)             # calculate the attention weights (1, 5, 5)\n",
    "        return torch.bmm(attn_weights, self.v(hidden_state)) # return the attention outputs (1, 5, 5) * (1, 5, 64) = (1, 5, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b1ccfa8-a435-47b8-96e4-6dd4a9fb0fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the multi-head attention\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    # initialize the class\n",
    "    def __init__(self, config):\n",
    "        # call the parent class\n",
    "        super().__init__()\n",
    "        \n",
    "        # create the attention heads\n",
    "        embed_dim = config.hidden_size         # 768\n",
    "        num_heads = config.num_attention_heads # 12\n",
    "        head_dim = embed_dim // num_heads      # 64\n",
    "\n",
    "        # create the attention heads\n",
    "        self.heads = nn.ModuleList(\n",
    "            [AttentionHead(embed_dim, head_dim) for _ in range(num_heads)] # create 12 attention heads where each K,V,Q is of size 64\n",
    "        )\n",
    "        # create the output linear transformation\n",
    "        self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "    # define the forward pass\n",
    "    def forward(self, hidden_state):           # hidden_state.size() = inputs_embeds.size() = (1, 5, 768) = (batch_size, seq_len, hidden_size)\n",
    "        # concatenate the attention outputs of the 12 attention heads\n",
    "        x = torch.cat([h(hidden_state) for h in self.heads], dim=-1)\n",
    "        # apply the output linear transformation\n",
    "        x = self.output_linear(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aeebdcb4-930d-4b0a-9eed-6caa0a6dadbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_attn = MultiHeadAttention(config)\n",
    "attn_output = multihead_attn(input_embeds)    \n",
    "attn_output.size() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d7da1ff-8662-4e61-b6d2-5870bc256f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHeadAttention(\n",
       "  (heads): ModuleList(\n",
       "    (0-11): 12 x AttentionHead(\n",
       "      (q): Linear(in_features=768, out_features=64, bias=True)\n",
       "      (k): Linear(in_features=768, out_features=64, bias=True)\n",
       "      (v): Linear(in_features=768, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (output_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "24cf61d5-15c3-4fec-9c4a-2e54f4a093ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # This step helps to visualize how each token in the input attends to other tokens.\n",
    "from bertviz import head_view\n",
    "from transformers import AutoModel\n",
    "\n",
    "model=AutoModel.from_pretrained(model_ckpt,output_attentions=True)\n",
    "\n",
    "sentence_a = \"time flies like an arrow\"\n",
    "sentence_b = \"fruit flies like a banana\"\n",
    "\n",
    "viz_inputs=tokenizer(sentence_a,sentence_b,return_tensors='pt')\n",
    "attention=model(**viz_inputs).attentions\n",
    "\n",
    "sentence_b_start = (viz_inputs.token_type_ids == 0).sum(dim=1)\n",
    "tokens=tokenizer.convert_ids_to_tokens(viz_inputs.input_ids[0])\n",
    "\n",
    "head_view(attention,tokens,sentence_b_start,heads=[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347394b4-a72b-4568-b34e-da53ec5e121d",
   "metadata": {},
   "source": [
    "### *The Feed-Forward Layer*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63da7e02-5037-4d19-aed9-3341107f0074",
   "metadata": {},
   "source": [
    " two-layer fully connected neural network, but with a twist: instead of processing the whole sequence of embeddings as a single vector, it processes each embedding indepenentl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "348e4f7b-9813-41fe-afad-53f34c1d4044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the point-wise feed forward network\n",
    "class FeedForward(nn.Module):\n",
    "    # initialize the class\n",
    "    def __init__(self, config):                                  \n",
    "        # call the parent class\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(config.hidden_size, config.intermediate_size) # project (1, 5, 768) -> (1, 5, 3072)\n",
    "        self.linear_2 = nn.Linear(config.intermediate_size, config.hidden_size) # project (1, 5, 3072) -> (1, 5, 768)\n",
    "        self.gelu = nn.GELU()                                                   # use the GELU activation function\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)                   # use the dropout probability from the config\n",
    "    \n",
    "    # define the forward pass of the Forward class\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "442f2a54-d7ad-4244-bd5c-581fb892f86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_outputs.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68f64d45-5d7d-48b0-ba28-69ea29fc4173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_forward = FeedForward(config)\n",
    "ff_outputs = feed_forward(attn_outputs)\n",
    "ff_outputs.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b185b1b-9f84-4613-af7a-5600dbd2437e",
   "metadata": {},
   "source": [
    "### *Adding Layer Normalization*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8344c078-855c-4c2e-ae0e-d2f1a4349b86",
   "metadata": {},
   "source": [
    "Transformer Encoder Layer with Layer Normalization\n",
    "- Each transformer encoder layer consists of two sub-layers: multi-head attention and a feed-forward layer.\n",
    "- *Layer Normalization* is applied before these sub-layers to stabilize and normalize the inputs.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "795ba341-2f15-44e6-a168-ad87d6c99f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layer_norm_1 = nn.LayerNorm(config.hidden_size)\n",
    "        self.layer_norm_2 = nn.LayerNorm(config.hidden_size)\n",
    "        self.attention = MultiHeadAttention(config)\n",
    "        self.feed_forward = FeedForward(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden_state = self.layer_norm_1(x)\n",
    "        x = x + self.attention(hidden_state)\n",
    "        x = x + self.feed_forward(self.layer_norm_2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe94c5f7-5b4e-4dab-9b2b-49e716a2713c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 5, 768]), torch.Size([1, 5, 768]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_layer = TransformerEncoderLayer(config)\n",
    "input_embeds.shape, encoder_layer(input_embeds).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df054bf-3012-4d76-a770-996fcd406298",
   "metadata": {},
   "source": [
    "### *Embedding Layer (Token + Positional Embeddings)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d8d356d-affc-4685-be33-64d991deb9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for embedding layer that combines token and position embeddings\n",
    "# position embeddings are learnable\n",
    "class Embeddings(nn.Module):\n",
    "    # initialize the class\n",
    "    def __init__(self, config):\n",
    "        # call the parent class\n",
    "        super().__init__()\n",
    "\n",
    "        # create the token and position embeddings \n",
    "        self.token_embeddings = nn.Embedding(config.vocab_size,     # 30522, the size of the vocabulary\n",
    "                                             config.hidden_size)    # 768, the hidden size of the model\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, # 512, maximum sequence length that this model might ever be used with\n",
    "                                                config.hidden_size)             # 768, the hidden size of the model\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size, eps=1e-12)            \n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    # define the forward pass of the embedding layer\n",
    "    def forward(self, input_ids):                                              # tensor([[ 2051, 10029,  2066,  2019,  8612]])\n",
    "        # Create position IDs for input sequence\n",
    "        seq_length = input_ids.size(1)                                         # 5\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long).unsqueeze(0) # tensor([[0, 1, 2, 3, 4]])\n",
    "        # Create token and position embeddings\n",
    "        token_embeddings = self.token_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        # Combine token and position embeddings\n",
    "        embeddings = token_embeddings + position_embeddings\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "06ca810a-4927-4ceb-812d-8b66d8657825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the embedding layer\n",
    "embedding_layer = Embeddings(config)\n",
    "# apply the embedding layer to the input_ids\n",
    "embedding_layer(inputs.input_ids).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c6e070-eb0b-47ca-9972-e593d33bc846",
   "metadata": {},
   "source": [
    "### *Full Transformer Encoder*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f846001a-a063-400d-81ae-c8ae89354446",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embeddings = Embeddings(config)\n",
    "        self.layers = nn.ModuleList([TransformerEncoderLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1480a26-deb3-4277-bacf-08adc1ea17bc",
   "metadata": {},
   "source": [
    "### *Classification Head*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "55791b06-86af-45ff-b870-6b625b67de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerForSequenceClassification(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.encoder = TransformerEncoder(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)[:, 0, :]\n",
    "        x = self.dropout(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79626be7-a561-4da9-ba9e-007096615ccc",
   "metadata": {},
   "source": [
    "### *Masked Attention in Decoder*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09fda134-931b-4a18-a094-6deadd066246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    dim_k = query.size(-1)\n",
    "    scores = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    return weights.bmm(value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ab27be-1aea-44ed-9d89-8ff0cff8d53a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
